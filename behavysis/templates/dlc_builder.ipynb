{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC Model Creation and Training Script\n",
    "\n",
    "**RUNNING THIS SCRIPT:** Run this script with the DEEPLABCUT conda environment.\n",
    "\n",
    "This script generates a DLC multi-animal model, which can even be used for single animals (in fact, training and inference is both faster too).\n",
    "\n",
    "The script follows the below steps, which are almost identical to the prescribed process [here](https://deeplabcut.github.io/DeepLabCut/docs/maDLC_UserGuide.html):\n",
    "\n",
    "1. Create a DLC project folder and config file. The config file stores the model's data, training, and inference configurations.\n",
    "1. Manually change the following parameters in the config file:\n",
    "   <!-- * `identity: true` (as we can identify each animal uniquely across frames) -->\n",
    "   - `individuals`: name for each animal (e.g. `mouse1`)\n",
    "   - `uniquebodyparts`: parts in the arena that are NOT the animal (e.g. `TopLeft`, `ColourMarking`)\n",
    "   - `multianimalbodyparts`: bodyparts for an animal (e.g. `Nose`)\n",
    "   - `numframes2pick`: The number of frames to extract from each video for labeling. A rule of thumb is ~500 frames overall is sufficient to train a model well.\n",
    "   <!-- * `batch_size: 32` (Speeds up computation for better GPUs). -->\n",
    "1. Load videos to be used for training into the project's `videos` folder and update the config file with a list of these videos.\n",
    "1. Randomly extract `n` (user specified) frames from each video and store in the `labeled-data` folder.\n",
    "   - NOTE: it can be useful to trim videos and import these to the project to get frames that you'd particularly like to label (e.g. close interaction in social experiments).\n",
    "1. Downsample all frames to `960 x 540 px` (or the resolution you'd like). Also update config file to reflect this resolution.\n",
    "1. Manually label frames\n",
    "1. Create combined training dataset from labeled frames\n",
    "1. Run training. The following training parameters are usually ideal:\n",
    "   - `saveiter = 5000`\n",
    "   - `maxiter = 50000`\n",
    "1. Evaluate statistic (optional - gives MAE but difficult to interrogate this single statistic).\n",
    "1. Test on novel video(s) and manually inspect tracking.\n",
    "\n",
    "NOTE: for experiments with multiple animals, the following parameters are usually ideal:\n",
    "\n",
    "- TODO: in pose_inference.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import yaml\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify project folder and name\n",
    "\n",
    "DLC models are usually stored in the `Z:\\PRJ-BowenLab\\PRJ-BowenLab\\DeepLabCut-Projects` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE\n",
    "root_dir = r\"/home/linux1/Desktop/models_training/3_CHAMBER_CUPS\"\n",
    "# CHANGE\n",
    "proj_name = \"3_CHAMBER_CUPS_BLACK_MICE_960x540px\"\n",
    "# Don't need to change\n",
    "experimenter = \"BowenLab\"\n",
    "# Can modify if running multiple GPU's at once\n",
    "gputouse = 0\n",
    "# Downsampling size for training frames\n",
    "# 960 x 540 is a good size\n",
    "res_width = 960\n",
    "res_height = 540\n",
    "\n",
    "# DON'T CHANGE\n",
    "proj_dir = os.path.join(root_dir, proj_name)\n",
    "config_fp = os.path.join(proj_dir, \"config.yaml\")\n",
    "\n",
    "display(os.path.isfile(config_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating project\n",
    "\n",
    "NOTE: don't need to run if project is already created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if porject doesn't exist yet\n",
    "if os.path.exists(proj_dir):\n",
    "    print(f\"NOT making project because it already exists: {proj_dir}\")\n",
    "else:\n",
    "    # Making placeholder vid\n",
    "    placeholder_fp = os.path.join(root_dir, \"placeholder_vid.mp4\")\n",
    "    cap = cv2.VideoWriter(\n",
    "        placeholder_fp,\n",
    "        cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "        15,\n",
    "        (res_width, res_height),\n",
    "    )\n",
    "    black_frame = np.zeros((res_height, res_width, 3), dtype=np.uint8)\n",
    "    for _ in range(15):\n",
    "        cap.write(black_frame)\n",
    "    cap.release()\n",
    "    # Creating project\n",
    "    temp_config_fp = deeplabcut.create_new_project(\n",
    "        project=proj_name,\n",
    "        experimenter=experimenter,\n",
    "        videos=[placeholder_fp],\n",
    "        working_directory=root_dir,\n",
    "        copy_videos=True,\n",
    "        multianimal=True,\n",
    "    )\n",
    "    # Renaming project to just proj_name\n",
    "    os.rename(src=os.path.dirname(temp_config_fp), dst=proj_dir)\n",
    "    # Updating config file with:\n",
    "    # animals are identifiable, updated project path, and batch size\n",
    "    deeplabcut.auxiliaryfunctions.edit_config(\n",
    "        config_fp,\n",
    "        {\n",
    "            \"identity\": True,\n",
    "            \"project_path\": proj_dir,\n",
    "            \"batch_size\": 8,\n",
    "        },\n",
    "    )\n",
    "    # Remove placeholding videos from project videos folder\n",
    "    os.remove(placeholder_fp)\n",
    "    os.remove(os.path.join(proj_dir, \"videos\", \"placeholder_vid.mp4\"))\n",
    "    # Making folder named \"videos_raw\" to store vids before downsampling\n",
    "    os.makedirs(os.path.join(proj_dir, \"videos_raw\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(proj_dir, \"test_on_novels\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually change config file parameters\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "Manually update the following parameters in the `config.yaml` file.\n",
    "\n",
    "- `individuals`: name for each animal (e.g. `mouse1`)\n",
    "- `uniquebodyparts`: parts in the arena that are NOT the animal (e.g. `TopLeft`, `ColourMarking`)\n",
    "- `multianimalbodyparts`: bodyparts for an animal (e.g. `Nose`)\n",
    "- `numframes2pick`: The number of frames to extract from each video for labeling. A rule of thumb is ~500 frames overall is sufficient to train a model well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw training videos\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "Copy training videos to the `<proj_dir>\\videos_raw` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling videos and saving to the `videos` folder\n",
    "\n",
    "Uses ffmpeg to downsample videos.\n",
    "\n",
    "Set the `res_width` and `res_height` values in the 2nd top Python cell (that has all the other settings for training this model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_vid(in_fp, out_fp, res_width, res_height):\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        in_fp,\n",
    "        \"-vf\",\n",
    "        f\"scale={res_width}:{res_height}\",\n",
    "        \"-c:v\",\n",
    "        \"h264\",\n",
    "        \"-preset\",\n",
    "        \"fast\",\n",
    "        \"-crf\",\n",
    "        \"20\",\n",
    "        \"-y\",\n",
    "        out_fp,\n",
    "    ]\n",
    "    os.makedirs(os.path.dirname(out_fp), exist_ok=True)\n",
    "    subprocess.run(cmd)\n",
    "\n",
    "\n",
    "for vid_fp in os.listdir(os.path.join(proj_dir, \"videos_raw\")):\n",
    "    downsample_vid(\n",
    "        in_fp=os.path.join(proj_dir, \"videos_raw\", vid_fp),\n",
    "        out_fp=os.path.join(proj_dir, \"videos\", vid_fp),\n",
    "        res_width=res_width,\n",
    "        res_height=res_height,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating configs file with the filepaths of our training videos\n",
    "\n",
    "This is required for DLC's extract frames step.\n",
    "It looks at the video filepaths in the configs file and extracts frames from those videos for labeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config_videos(proj_dir):\n",
    "    # Getting folder names for videos and labeled data\n",
    "    videos_dir = os.path.join(proj_dir, \"videos\")\n",
    "    labeled_dir = os.path.join(proj_dir, \"labeled-data\")\n",
    "    video_sets = {}\n",
    "    # For each video, store vid dims in video_configs\n",
    "    for j in os.listdir(videos_dir):\n",
    "        vid_fp = os.path.join(videos_dir, j)\n",
    "        # Getting video dimensions\n",
    "        cap = cv2.VideoCapture(vid_fp)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        # Adding to video_sets dict\n",
    "        video_sets[vid_fp] = {\"crop\": f\"0, {width}, 0, {height}\"}\n",
    "        # Closing video\n",
    "        cap.release()\n",
    "    # For all labeled-data frames (corresponding to videos)\n",
    "    # Overwrites the video dimensions because these are the actual frames\n",
    "    # Used for training\n",
    "    for i in os.listdir(labeled_dir):\n",
    "        # Not considering labeled data\n",
    "        if re.search(\"_labeled$\", i):\n",
    "            continue\n",
    "        # Getting one of the image frames in the\n",
    "        # labeled data dict (to get video dimensions)\n",
    "        fp_ls = [j for j in os.listdir(os.path.join(labeled_dir, i)) if re.search(\"\\.png$\", j)]\n",
    "        # If no frames, skip\n",
    "        if len(fp_ls) == 0:\n",
    "            continue\n",
    "        # Getting frame fp and video fp\n",
    "        vid_fp = os.path.join(videos_dir, f\"{i}.mp4\")\n",
    "        png_fp = os.path.join(labeled_dir, i, fp_ls[0])\n",
    "        # Getting video dimensions\n",
    "        height, width, ch = cv2.imread(png_fp).shape\n",
    "        video_sets[vid_fp] = {\"crop\": f\"0, {width}, 0, {height}\"}\n",
    "    # Updating configs file with video_sets\n",
    "    deeplabcut.auxiliaryfunctions.edit_config(config_fp, {\"video_sets\": video_sets})\n",
    "\n",
    "\n",
    "update_config_videos(proj_dir)\n",
    "\n",
    "# # Regular DLC implementation (does not consider extracted frame dimensions)\n",
    "# deeplabcut.add_new_videos(\n",
    "#     config_path,\n",
    "#     r\"z:\\PRJ-BowenLab\\PRJ-BowenLab\\DeepLabCut-Projects\\SFC_WHITE_MICE\\videos\",\n",
    "#     copy_videos=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract frames\n",
    "\n",
    "Randomly extract `n` (user specified) frames from each video and store in the `labeled-data` folder.\n",
    "\n",
    "NOTE: edit the `numframes2pick` value in `configs.yaml` to change the number of frames extracted.\n",
    "~500 frames overall is sufficient to train a model well.\n",
    "\n",
    "NOTE: it can be useful to trim videos and import these to the project to get frames that you'd particularly like to label (e.g. close interaction in social experiments).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING FRAMES\n",
    "\n",
    "# Getting folder names for videos and labeled data\n",
    "videos_dir = os.path.join(proj_dir, \"videos\")\n",
    "labeled_dir = os.path.join(proj_dir, \"labeled-data\")\n",
    "# Get `n` from config file\n",
    "with open(config_fp, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "n = config[\"numframes2pick\"]\n",
    "# For each video, extract `n` frames\n",
    "for i in os.listdir(videos_dir):\n",
    "    # Getting video fp\n",
    "    vid_name = os.path.splitext(i)[0]\n",
    "    vid_fp = os.path.join(videos_dir, i)\n",
    "    vid_labeled_dir = os.path.join(labeled_dir, vid_name)\n",
    "    # Opening video\n",
    "    print(f\"Extracting {n} frames from {vid_name}\")\n",
    "    vid = cv2.VideoCapture(vid_fp)\n",
    "    # Getting total frames in video\n",
    "    total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # Getting `k` random frames\n",
    "    frame_ids = np.random.choice(total_frames, n, replace=False).astype(int)\n",
    "    # Creating folder for video\n",
    "    os.makedirs(vid_labeled_dir, exist_ok=True)\n",
    "    # For each frame in randomly selected set, save frame\n",
    "    for j in sorted(frame_ids):\n",
    "        print(f\"    saving frame {j:06} ... \")\n",
    "        # Seeking to frame\n",
    "        vid.set(cv2.CAP_PROP_POS_FRAMES, j)\n",
    "        # Reading frame\n",
    "        ret, frame = vid.read()\n",
    "        # Saving frame\n",
    "        if ret:\n",
    "            cv2.imwrite(os.path.join(vid_labeled_dir, f\"img{j:06}.png\"), frame)\n",
    "    # Closing video\n",
    "    vid.release()\n",
    "\n",
    "# # Regular DLC implementation (any error will entirely halt the process)\n",
    "# deeplabcut.extract_frames(\n",
    "#     config_path,\n",
    "#     mode=\"automatic\",  # \"automatic\"/\"manual\"\n",
    "#     algo='uniform',  # \"uniform\"/\"kmeans\"\n",
    "#     userfeedback=False,  # True/False\n",
    "#     crop=False  # keep as False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: check that all frames are labelled without deleting rows and images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabcut.create_training_dataset(config_fp)\n",
    "\n",
    "deeplabcut.create_multianimaltraining_dataset(config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Note the pytorch training configs. These particular configs are stored in the `dlc-models-pytorch/.../train/pytorch_config.yaml` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(\n",
    "    config_fp,\n",
    "    shuffle=1,\n",
    "    trainingsetindex=0,\n",
    "    gputouse=gputouse,\n",
    "    max_snapshots_to_keep=5,\n",
    "    autotune=False,\n",
    "    displayiters=100,\n",
    "    # saveiters=5000,\n",
    "    save_epochs=50,\n",
    "    # maxiters=50000, # Can change - 50000 is good\n",
    "    epochs=1000,\n",
    "    allow_growth=True,\n",
    "    pytorch_cfg_updates={\n",
    "        \"runner.gpus\": [gputouse],\n",
    "        \"runner.snapshots.max_snapshots\": 5,\n",
    "        \"runner.snapshots.save_epochs\": 50,\n",
    "        \"runner.snapshots.save_optimizer_state\": False,\n",
    "        \"train_settings.batch_size\": 8,\n",
    "        \"train_settings.dataloader_workers\": 1,\n",
    "        \"train_settings.dataloader_pin_memory\": True,\n",
    "        \"train_settings.display_iters\": 100,\n",
    "        \"train_settings.epochs\": 1000,\n",
    "        \"train_settings.seed\": 42,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "\n",
    "Optional - this gives a Mean Absolute Error, which is difficult to interrogate.\n",
    "\n",
    "It is advisable to instead run the model on some novel videos and inspect its performance by eye.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabcut.evaluate_network(config_fp, plotting=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on novel video(s) and manually inspect tracking\n",
    "\n",
    "Firstly, make a folder in `proj_dir` called `novel_videos` and add some novel videos.\n",
    "\n",
    "Then run the following code block, which runs the model on these video.\n",
    "\n",
    "Inspect these videos and if performance is not satisfactory, label more frames and rerun training.\n",
    "\n",
    "Notes for inspection:\n",
    "\n",
    "- Importantly, do bodypoints track well.\n",
    "- For multi-animal experiments, do points assemble to a single animal well (even if the identity is incorrect),\n",
    "- For multi-animal experiments, don't worry about swapping identities - a postprocessing step is done in our pipeline which fixes the identities to the markings/non-markings of each animal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_vids_dir = os.path.join(proj_dir, \"test_on_novels\")\n",
    "assert os.path.exists(novel_vids_dir)\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(os.path.join(novel_vids_dir, \"out\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "os.makedirs(os.path.join(novel_vids_dir, \"out\"), exist_ok=True)\n",
    "\n",
    "deeplabcut.analyze_videos(\n",
    "    config=config_fp,\n",
    "    videos=os.path.join(novel_vids_dir, \"in\"),\n",
    "    videotype=\".mp4\",\n",
    "    destfolder=os.path.join(novel_vids_dir, \"out\"),\n",
    "    auto_track=True,\n",
    "    gputouse=gputouse,\n",
    "    save_as_csv=False,\n",
    "    calibrate=False,\n",
    "    identity_only=False,\n",
    "    allow_growth=True,\n",
    "    # torch_kwargs={\n",
    "    #     \"device\": [gputouse],\n",
    "    # },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(\n",
    "    config=config_fp,\n",
    "    videos=os.path.join(novel_vids_dir, \"in\"),\n",
    "    videotype=\".mp4\",\n",
    "    color_by=\"individual\",\n",
    "    destfolder=os.path.join(novel_vids_dir, \"out\"),\n",
    "    overwrite=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
